# Analise-Multimodal-de-Sentimento
Sistema de InteligÃªncia Artificial que analisa sentimento em vÃ­deos combinando **trÃªs modalidades**: texto (transcriÃ§Ã£o), expressÃµes faciais e tom de voz.
---
title: AnÃ¡lise Multimodal de Sentimento
emoji: ğŸ¬
colorFrom: blue
colorTo: purple
sdk: gradio
sdk_version: 4.0.0
app_file: app.py
pinned: false
---

# ğŸ¬ AnÃ¡lise de Sentimento Multimodal

Sistema de InteligÃªncia Artificial que analisa sentimento em vÃ­deos combinando **trÃªs modalidades**: texto (transcriÃ§Ã£o), expressÃµes faciais e tom de voz.

ğŸ”— **Demo ao vivo:** https://huggingface.co/spaces/Danielfonseca1212/Multimodal

---

## ğŸ¯ O que faz?

Analisa vÃ­deos de reviews/depoimentos e determina o sentimento geral (positivo, negativo ou neutro) combinando:

| Modalidade | Tecnologia | O que analisa |
|------------|-----------|---------------|
| ğŸ“ **Texto** | Whisper + BERT | TranscriÃ§Ã£o e sentimento das palavras |
| ğŸ˜Š **Visual** | DeepFace | ExpressÃµes faciais e emoÃ§Ãµes |
| ğŸµ **Ãudio** | Librosa | Pitch, energia e prosÃ³dia da voz |

**Diferencial:** Detecta **inconsistÃªncias** entre o que a pessoa diz e sua expressÃ£o facial/tom de voz.

---

## ğŸš€ Como usar

1. **Acesse** o link do Space
2. **FaÃ§a upload** de um vÃ­deo (mÃ¡x 60 segundos, 100MB)
3. **Aguarde** o processamento (~30-60 segundos)
4. **Receba** a anÃ¡lise combinada das 3 modalidades

### ğŸ’¡ Dicas para melhores resultados:
- Use vÃ­deos com **rosto visÃ­vel** e bem iluminado
- **Ãudio claro** ajuda na transcriÃ§Ã£o
- Evite vÃ­deos muito **escuros ou com muito ruÃ­do**

---## ğŸ—ï¸ Arquitetura do Sistema

VÃ­deo de Entrada
â”‚
â”œâ”€â”€â†’ ğŸ”Š Ãudio â”€â”€â†’ Whisper â”€â”€â†’ Texto â”€â”€â†’ BERT â”€â”€â†’ Sentimento Texto (40%)
â”‚
â”œâ”€â”€â†’ ğŸ¥ Frames â”€â”€â†’ DeepFace â”€â”€â†’ ExpressÃµes â”€â”€â†’ Sentimento Visual (35%)
â”‚
â””â”€â”€â†’ ğŸµ Ãudio â”€â”€â†’ Librosa â”€â”€â†’ Features â”€â”€â†’ Sentimento Ãudio (25%)
â”‚
â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FusÃ£o Ponderada â”‚ â† Detecta inconsistÃªncias
â”‚  Weighted Voting â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â†“
Resultado Final + ExplicaÃ§Ã£o
plain
Copy

---

## ğŸ› ï¸ Stack TecnolÃ³gico

| Categoria | Tecnologias |
|-----------|-------------|
| **Linguagem** | Python 3.13 |
| **Deep Learning** | PyTorch, Transformers (Hugging Face) |
| **VisÃ£o Computacional** | OpenCV, DeepFace |
| **Processamento de Ãudio** | Librosa, SoundFile |
| **VÃ­deo** | MoviePy, ImageIO |
| **Deploy** | Gradio, Hugging Face Spaces |
| **ML Ops** | TensorFlow (backend DeepFace) |

### Modelos Utilizados:
- **Whisper Tiny** (OpenAI) - TranscriÃ§Ã£o de Ã¡udio
- **DistilBERT MultilÃ­ngue** - AnÃ¡lise de sentimento textual
- **RetinaFace + FER** (DeepFace) - DetecÃ§Ã£o facial e reconhecimento de emoÃ§Ãµes

---

## ğŸ“Š Exemplo de Resultado

### Input:
VÃ­deo de 15s de um cliente falando sobre um produto

### Output:
âœ… POSITIVO | Score: 4.2/5
ğŸ“Š AnÃ¡lise por Modalidade:
â”œâ”€ ğŸ“ Texto: POSITIVO (95% confianÃ§a)
â”‚  "Adorei o produto, superou minhas expectativas..."
â”œâ”€ ğŸ˜Š Visual: POSITIVO (82% confianÃ§a, 12 frames)
â”‚  ExpressÃ£o: predominantemente 'happy'
â””â”€ ğŸµ Ãudio: POSITIVO (75% confianÃ§a, 185Hz)
Pitch elevado indica entusiasmo
âœ… Todas as modalidades concordam
plain
Copy

### Caso de InconsistÃªncia:
âš ï¸ NEUTRO | Score: 3.1/5
ğŸ“Š AnÃ¡lise por Modalidade:
â”œâ”€ ğŸ“ Texto: POSITIVO (88% confianÃ§a)
â”‚  "O produto Ã© Ã³timo, recomendo..."
â”œâ”€ ğŸ˜Š Visual: NEUTRO (45% confianÃ§a, 10 frames)
â”‚  ExpressÃ£o: predominantemente 'neutral'
â””â”€ ğŸµ Ãudio: NEUTRO (60% confianÃ§a, 145Hz)
Tom de voz monÃ³tono
âš ï¸ ATENÃ‡ÃƒO: InconsistÃªncia detectada!
O que foi dito (positivo) nÃ£o corresponde Ã 
expressÃ£o facial e tom de voz (neutros).
plain
Copy

---

## ğŸ”¬ Base CientÃ­fica

Este sistema implementa tÃ©cnicas de **Multimodal Fusion** baseadas em pesquisas recentes:

> "A fusÃ£o de mÃºltiplas modalidades (texto, Ã¡udio, visual) supera a anÃ¡lise unimodal em 15-20% de acurÃ¡cia na detecÃ§Ã£o de sentimentos."  
> â€” [MDPI Electronics, 2025](https://www.mdpi.com/2079-9292/14/20/4015)

**TÃ©cnica de fusÃ£o:** Weighted Voting Adaptativo  
- Peso inicial: Texto 40%, Visual 35%, Ãudio 25%
- Ajuste dinÃ¢mico baseado na confianÃ§a de cada modalidade
- DetecÃ§Ã£o automÃ¡tica de inconsistÃªncias entre modalidades

---

## âš™ï¸ InstalaÃ§Ã£o Local

```bash
# 1. Clone o repositÃ³rio
git clone https://github.com/SEU_USUARIO/analise-sentimento-multimodal.git
cd analise-sentimento-multimodal

# 2. Crie ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate  # Windows

# 3. Instale dependÃªncias
pip install -r requirements.txt

# 4. Execute
python app.py
Acesse: http://localhost:7860
ğŸš€ Deploy no Hugging Face Spaces
bash
Copy
# 1. Instale o CLI do Hugging Face
pip install huggingface-hub

# 2. FaÃ§a login
huggingface-cli login

# 3. Crie o Space
huggingface-cli repo create nome-do-space --type space --sdk gradio

# 4. Clone, adicione arquivos e push
git clone https://huggingface.co/spaces/SEU_USUARIO/nome-do-space
cd nome-do-space
# Copie app.py, requirements.txt, README.md
git add .
git commit -m "Deploy inicial"
git push
ğŸ“ˆ MÃ©tricas e Performance
Table
Copy
Aspecto	Valor
Tempo de processamento	~30-60s para vÃ­deo de 30s
Limite de tamanho	100MB (HF Spaces gratuito)
Limite de duraÃ§Ã£o	60 segundos
Frames analisados	AtÃ© 20 frames por vÃ­deo
Idiomas suportados	PortuguÃªs, InglÃªs (e outros via Whisper)
ğŸ¯ Casos de Uso
E-commerce: AnÃ¡lise automÃ¡tica de reviews em vÃ­deo
Atendimento ao Cliente: AvaliaÃ§Ã£o de chamadas de suporte
Pesquisa de Mercado: AnÃ¡lise de entrevistas de satisfaÃ§Ã£o
MÃ­dias Sociais: Monitoramento de sentimento em vÃ­deos
Recursos Humanos: AnÃ¡lise de entrevistas de candidatos
ğŸ›¡ï¸ LimitaÃ§Ãµes e ConsideraÃ§Ãµes
Table
Copy
LimitaÃ§Ã£o	ExplicaÃ§Ã£o
Privacidade	VÃ­deos sÃ£o processados em memÃ³ria e nÃ£o armazenados
PrecisÃ£o	Dependente da qualidade do vÃ­deo (iluminaÃ§Ã£o, Ã¡udio)
Contexto cultural	ExpressÃµes faciais podem variar entre culturas
Vieses de modelo	Modelos prÃ©-treinados podem conter vieses dos dados originais
ğŸ”§ Troubleshooting
Erro: "VÃ­deo muito longo"
SoluÃ§Ã£o: Corte o vÃ­deo para menos de 60 segundos usando:
bash
Copy
ffmpeg -i input.mp4 -t 30 -c copy output.mp4
Erro: "Nenhum rosto detectado"
Causa: IluminaÃ§Ã£o ruim ou rosto muito pequeno
SoluÃ§Ã£o: Use vÃ­deos com rosto prÃ³ximo e bem iluminado
Erro: "TranscriÃ§Ã£o vazia"
Causa: Ãudio muito baixo ou ruÃ­do excessivo
SoluÃ§Ã£o: Verifique se o Ã¡udio estÃ¡ claro e sem mÃºsica de fundo alta
ğŸ¤ ContribuiÃ§Ã£o
ContribuiÃ§Ãµes sÃ£o bem-vindas! Para contribuir:
Fork o projeto
Crie uma branch (git checkout -b feature/nova-funcionalidade)
Commit suas mudanÃ§as (git commit -m 'Adiciona nova funcionalidade')
Push para a branch (git push origin feature/nova-funcionalidade)
Abra um Pull Request
Ideias para melhorias:
[ ] Suporte a mais idiomas
[ ] AnÃ¡lise de mÃºltiplas pessoas no vÃ­deo
[ ] ExportaÃ§Ã£o de relatÃ³rios em PDF
[ ] ComparaÃ§Ã£o lado a lado de dois vÃ­deos
[ ] Dashboard com histÃ³rico de anÃ¡lises
ğŸ“ LicenÃ§a
Este projeto estÃ¡ licenciado sob a licenÃ§a MIT - veja o arquivo LICENSE para detalhes.
ğŸ‘¨â€ğŸ’» Autor
[Seu Nome]
ğŸ”— LinkedIn | ğŸ™ GitHub | ğŸŒ PortfÃ³lio
ğŸ™ Agradecimentos
Hugging Face por disponibilizar modelos open-source
OpenAI pelo Whisper
Serengil pelo DeepFace
Comunidade open-source pelas ferramentas de ML
â­ Se este projeto te ajudou, deixe uma star no repositÃ³rio!
plain
Copy

---

**Substitua:**
- `SEU_USUARIO` pelo seu usuÃ¡rio do GitHub/HF
- `nome-do-space` pelo nome do seu Space
- `[Seu Nome]` pelo seu nome real
- Os links de LinkedIn/GitHub pelos seus

Quer que eu adicione mais alguma seÃ§Ã£o, como **"Roadmap"** ou **"Benchmarks comparativos"**?
https://huggingface.co/spaces/Danielfonseca1212/Multimodal  link do sistema atualize as informaÃ§Ãµes
Edit
Copy
Share
Aqui estÃ¡ o README.md atualizado com o link do seu sistema:
Markdown
Copy
Code
Preview
---
title: AnÃ¡lise Multimodal de Sentimento
emoji: ğŸ¬
colorFrom: blue
colorTo: purple
sdk: gradio
sdk_version: 4.0.0
app_file: app.py
pinned: false
---

# ğŸ¬ AnÃ¡lise de Sentimento Multimodal

Sistema de InteligÃªncia Artificial que analisa sentimento em vÃ­deos combinando **trÃªs modalidades**: texto (transcriÃ§Ã£o), expressÃµes faciais e tom de voz.

ğŸ”— **Demo ao vivo:** [https://huggingface.co/spaces/Danielfonseca1212/Multimodal](https://huggingface.co/spaces/Danielfonseca1212/Multimodal)

---

## ğŸ¯ O que faz?

Analisa vÃ­deos de reviews/depoimentos e determina o sentimento geral (positivo, negativo ou neutro) combinando:

| Modalidade | Tecnologia | O que analisa |
|------------|-----------|---------------|
| ğŸ“ **Texto** | Whisper + BERT | TranscriÃ§Ã£o e sentimento das palavras |
| ğŸ˜Š **Visual** | DeepFace | ExpressÃµes faciais e emoÃ§Ãµes |
| ğŸµ **Ãudio** | Librosa | Pitch, energia e prosÃ³dia da voz |

**Diferencial:** Detecta **inconsistÃªncias** entre o que a pessoa diz e sua expressÃ£o facial/tom de voz.

---

## ğŸš€ Como usar

1. **Acesse:** [https://huggingface.co/spaces/Danielfonseca1212/Multimodal](https://huggingface.co/spaces/Danielfonseca1212/Multimodal)
2. **FaÃ§a upload** de um vÃ­deo (mÃ¡x 60 segundos, 100MB)
3. **Aguarde** o processamento (~30-60 segundos)
4. **Receba** a anÃ¡lise combinada das 3 modalidades

### ğŸ’¡ Dicas para melhores resultados:
- Use vÃ­deos com **rosto visÃ­vel** e bem iluminado
- **Ãudio claro** ajuda na transcriÃ§Ã£o
- Evite vÃ­deos muito **escuros ou com muito ruÃ­do**

---

## ğŸ—ï¸ Arquitetura do Sistema
VÃ­deo de Entrada
â”‚
â”œâ”€â”€â†’ ğŸ”Š Ãudio â”€â”€â†’ Whisper â”€â”€â†’ Texto â”€â”€â†’ BERT â”€â”€â†’ Sentimento Texto (40%)
â”‚
â”œâ”€â”€â†’ ğŸ¥ Frames â”€â”€â†’ DeepFace â”€â”€â†’ ExpressÃµes â”€â”€â†’ Sentimento Visual (35%)
â”‚
â””â”€â”€â†’ ğŸµ Ãudio â”€â”€â†’ Librosa â”€â”€â†’ Features â”€â”€â†’ Sentimento Ãudio (25%)
â”‚
â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FusÃ£o Ponderada â”‚ â† Detecta inconsistÃªncias
â”‚  Weighted Voting â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â†“
Resultado Final + ExplicaÃ§Ã£o
plain
Copy

---

## ğŸ› ï¸ Stack TecnolÃ³gico

| Categoria | Tecnologias |
|-----------|-------------|
| **Linguagem** | Python 3.13 |
| **Deep Learning** | PyTorch, Transformers (Hugging Face) |
| **VisÃ£o Computacional** | OpenCV, DeepFace |
| **Processamento de Ãudio** | Librosa, SoundFile |
| **VÃ­deo** | MoviePy, ImageIO |
| **Deploy** | Gradio, Hugging Face Spaces |
| **ML Ops** | TensorFlow (backend DeepFace) |

### Modelos Utilizados:
- **Whisper Tiny** (OpenAI) - TranscriÃ§Ã£o de Ã¡udio
- **DistilBERT MultilÃ­ngue** - AnÃ¡lise de sentimento textual
- **RetinaFace + FER** (DeepFace) - DetecÃ§Ã£o facial e reconhecimento de emoÃ§Ãµes

---

## ğŸ“Š Exemplo de Resultado

### Input:
VÃ­deo de 15s de um cliente falando sobre um produto

### Output:
âœ… POSITIVO | Score: 4.2/5
ğŸ“Š AnÃ¡lise por Modalidade:
â”œâ”€ ğŸ“ Texto: POSITIVO (95% confianÃ§a)
â”‚  "Adorei o produto, superou minhas expectativas..."
â”œâ”€ ğŸ˜Š Visual: POSITIVO (82% confianÃ§a, 12 frames)
â”‚  ExpressÃ£o: predominantemente 'happy'
â””â”€ ğŸµ Ãudio: POSITIVO (75% confianÃ§a, 185Hz)
Pitch elevado indica entusiasmo
âœ… Todas as modalidades concordam
plain
Copy

### Caso de InconsistÃªncia:
âš ï¸ NEUTRO | Score: 3.1/5
ğŸ“Š AnÃ¡lise por Modalidade:
â”œâ”€ ğŸ“ Texto: POSITIVO (88% confianÃ§a)
â”‚  "O produto Ã© Ã³timo, recomendo..."
â”œâ”€ ğŸ˜Š Visual: NEUTRO (45% confianÃ§a, 10 frames)
â”‚  ExpressÃ£o: predominantemente 'neutral'
â””â”€ ğŸµ Ãudio: NEUTRO (60% confianÃ§a, 145Hz)
Tom de voz monÃ³tono
âš ï¸ ATENÃ‡ÃƒO: InconsistÃªncia detectada!
O que foi dito (positivo) nÃ£o corresponde Ã 
expressÃ£o facial e tom de voz (neutros).
plain
Copy

---

## ğŸ”¬ Base CientÃ­fica

Este sistema implementa tÃ©cnicas de **Multimodal Fusion** baseadas em pesquisas recentes:

> "A fusÃ£o de mÃºltiplas modalidades (texto, Ã¡udio, visual) supera a anÃ¡lise unimodal em 15-20% de acurÃ¡cia na detecÃ§Ã£o de sentimentos."  
> â€” [MDPI Electronics, 2025](https://www.mdpi.com/2079-9292/14/20/4015)

**TÃ©cnica de fusÃ£o:** Weighted Voting Adaptativo  
- Peso inicial: Texto 40%, Visual 35%, Ãudio 25%
- Ajuste dinÃ¢mico baseado na confianÃ§a de cada modalidade
- DetecÃ§Ã£o automÃ¡tica de inconsistÃªncias entre modalidades

---

## âš™ï¸ InstalaÃ§Ã£o Local

```bash
# 1. Clone o repositÃ³rio
git clone https://github.com/Danielfonseca1212/analise-sentimento-multimodal.git
cd analise-sentimento-multimodal

# 2. Crie ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate  # Windows

# 3. Instale dependÃªncias
pip install -r requirements.txt

# 4. Execute
python app.py
Acesse: http://localhost:7860
ğŸš€ Deploy no Hugging Face Spaces
bash
Copy
# 1. Instale o CLI do Hugging Face
pip install huggingface-hub

# 2. FaÃ§a login
huggingface-cli login

# 3. Crie o Space
huggingface-cli repo create Multimodal --type space --sdk gradio

# 4. Clone, adicione arquivos e push
git clone https://huggingface.co/spaces/Danielfonseca1212/Multimodal
cd Multimodal
# Copie app.py, requirements.txt, README.md
git add .
git commit -m "Deploy inicial"
git push
ğŸ“ˆ MÃ©tricas e Performance
Table
Copy
Aspecto	Valor
Tempo de processamento	~30-60s para vÃ­deo de 30s
Limite de tamanho	100MB (HF Spaces gratuito)
Limite de duraÃ§Ã£o	60 segundos
Frames analisados	AtÃ© 20 frames por vÃ­deo
Idiomas suportados	PortuguÃªs, InglÃªs (e outros via Whisper)
ğŸ¯ Casos de Uso
E-commerce: AnÃ¡lise automÃ¡tica de reviews em vÃ­deo
Atendimento ao Cliente: AvaliaÃ§Ã£o de chamadas de suporte
Pesquisa de Mercado: AnÃ¡lise de entrevistas de satisfaÃ§Ã£o
MÃ­dias Sociais: Monitoramento de sentimento em vÃ­deos
Recursos Humanos: AnÃ¡lise de entrevistas de candidatos
ğŸ›¡ï¸ LimitaÃ§Ãµes e ConsideraÃ§Ãµes
Table
Copy
LimitaÃ§Ã£o	ExplicaÃ§Ã£o
Privacidade	VÃ­deos sÃ£o processados em memÃ³ria e nÃ£o armazenados
PrecisÃ£o	Dependente da qualidade do vÃ­deo (iluminaÃ§Ã£o, Ã¡udio)
Contexto cultural	ExpressÃµes faciais podem variar entre culturas
Vieses de modelo	Modelos prÃ©-treinados podem conter vieses dos dados originais
ğŸ”§ Troubleshooting
Erro: "VÃ­deo muito longo"
SoluÃ§Ã£o: Corte o vÃ­deo para menos de 60 segundos usando:
bash
Copy
ffmpeg -i input.mp4 -t 30 -c copy output.mp4
Erro: "Nenhum rosto detectado"
Causa: IluminaÃ§Ã£o ruim ou rosto muito pequeno
SoluÃ§Ã£o: Use vÃ­deos com rosto prÃ³ximo e bem iluminado
Erro: "TranscriÃ§Ã£o vazia"
Causa: Ãudio muito baixo ou ruÃ­do excessivo
SoluÃ§Ã£o: Verifique se o Ã¡udio estÃ¡ claro e sem mÃºsica de fundo alta
ğŸ¤ ContribuiÃ§Ã£o
ContribuiÃ§Ãµes sÃ£o bem-vindas! Para contribuir:
Fork o projeto
Crie uma branch (git checkout -b feature/nova-funcionalidade)
Commit suas mudanÃ§as (git commit -m 'Adiciona nova funcionalidade')
Push para a branch (git push origin feature/nova-funcionalidade)
Abra um Pull Request
Ideias para melhorias:
[ ] Suporte a mais idiomas
[ ] AnÃ¡lise de mÃºltiplas pessoas no vÃ­deo
[ ] ExportaÃ§Ã£o de relatÃ³rios em PDF
[ ] ComparaÃ§Ã£o lado a lado de dois vÃ­deos
[ ] Dashboard com histÃ³rico de anÃ¡lises
ğŸ“ LicenÃ§a
Este projeto estÃ¡ licenciado sob a licenÃ§a MIT - veja o arquivo LICENSE para detalhes.
ğŸ‘¨â€ğŸ’» Autor
Daniel Fonseca
ğŸ”— LinkedIn | ğŸ™ GitHub | ğŸš€ Hugging Face
ğŸ™ Agradecimentos
Hugging Face por disponibilizar modelos open-source
OpenAI pelo Whisper
Serengil pelo DeepFace
Comunidade open-source pelas ferramentas de ML
â­ Se este projeto te ajudou, deixe uma star no repositÃ³rio!
plain
Copy

---

**AtualizaÃ§Ãµes feitas:**
- âœ… Link do demo: `https://huggingface.co/spaces/Danielfonseca1212/Multimodal`
- âœ… Seu nome: **Daniel Fonseca**
- âœ… Seu usuÃ¡rio GitHub: `Danielfonseca1212`
- âœ… Seu perfil HF: `Danielfonseca1212`

**Para atualizar no HF Spaces:**
1. Edite o arquivo `README.md` no seu Space
2. Cole o conteÃºdo acima
3. Commit as mudanÃ§as

## ğŸ—ï¸ Arquitetura do Sistema

